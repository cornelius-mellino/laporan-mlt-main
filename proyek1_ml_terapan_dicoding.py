# -*- coding: utf-8 -*-
"""proyek1-ml-terapan-dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JJYG73jLdzPN_d5nUJsJ5OnqMKDuP702

# 1. Load and Explore Data
"""

import pandas as pd
import matplotlib.pyplot as plt

df_train = pd.read_csv("loan-train.csv")
df_train.head()

df_train.describe()

df_train.info()

df_val = pd.read_csv("loan-test.csv")
df_val.describe()

df_val.info()

"""# 2. Cek Validitas Data

## 2.1. Pemeriksaan dan penggantian null.

Bila terdapat data yang null maka akan diisi dengan suatu nilai. Nilai pengisinya bisa didapatkan dari penghitungan rata-rata (mean), atau dari penghitungan modusnya (mode).
"""

import missingno as msno

df_train.isna().sum()

df_val.isna().sum()

msno.matrix(df_train)

msno.matrix(df_val)

# Gantikan nilai null di semua fitur atau variabel yang memiliki nilai null.
# Untuk fitur numerikal dipakai fungsi mean() untuk mengisi nilai null dengan nilai rata-rata.
# Untuk fitur kategorikal dipakai fungsi mode() untuk mengisi nilai null dengan nilai terbanyak / modus.

df_train['Gender'].fillna(df_train['Gender'].mode()[0], inplace=True)
df_val['Gender'].fillna(df_val['Gender'].mode()[0], inplace=True)

df_train['Married'].fillna(df_train['Married'].mode()[0], inplace=True)
#df_val['Married'].fillna(df_val['Married'].mode()[0], inplace=True)

df_train['Dependents'].fillna(df_train['Dependents'].mode()[0], inplace=True)
df_val['Dependents'].fillna(df_val['Dependents'].mode()[0], inplace=True)

df_train['Self_Employed'].fillna(df_train['Self_Employed'].mode()[0], inplace=True)
df_val['Self_Employed'].fillna(df_val['Self_Employed'].mode()[0], inplace=True)

df_train['LoanAmount'].fillna(df_train['LoanAmount'].mean(), inplace=True)
df_val['LoanAmount'].fillna(df_val['LoanAmount'].mean(), inplace=True)

df_train['Loan_Amount_Term'].fillna(df_train['Loan_Amount_Term'].mean(), inplace=True)
df_val['Loan_Amount_Term'].fillna(df_val['Loan_Amount_Term'].mean(), inplace=True)

df_train['Credit_History'].fillna(df_train['Credit_History'].mode()[0], inplace=True)
df_val['Credit_History'].fillna(df_val['Credit_History'].mode()[0], inplace=True)

msno.matrix(df_train)

msno.matrix(df_val)

"""## 2.2. Mengubah nilai kategorikal menjadi numerikal
Nilai-nilai pada fungsi kategorikal sebaiknya diubah menjadi numerik agar model machine learning berkinerja optimal.
"""

from sklearn.preprocessing import LabelEncoder

df_train.Loan_Status = df_train.Loan_Status.replace({"Y": 1, "N" : 0})

features = ['Gender', 'Married', 'Self_Employed', 'Property_Area','Education', 'Dependents']
encoder = LabelEncoder()
for col in features:
    df_train[col] = encoder.fit_transform(df_train[col])
    df_val[col] = encoder.fit_transform(df_val[col])

df_train.head()

df_val.head()

"""## 2.3. Potong fitur Loan_ID"""

df_train.drop(columns='Loan_ID')
df_val.drop(columns='Loan_ID')

"""## 2.4. Periksa data Jenis Kelamin / Gender

Female = 0

Male = 1
"""

plt.hist(df_train.Gender)
plt.show()

df_train.Gender.value_counts()

"""## 2.5. Periksa data Status Pernikahan / Married
No = 0

Yes = 1
"""

plt.hist(df_train.Married)
plt.show()

df_train.Married.value_counts()

"""## 2.6. Periksa data Jumlah Tanggungan / Dependents
Nilai: 0, 1, 2, 3
"""

plt.hist(df_train.Dependents)
plt.show()

df_train.Dependents.value_counts()

"""## 2.7. Periksa data Pendidikan Terakhir / Education
Graduate = 0

Not Graduate = 1
"""

plt.hist(df_train.Education)
plt.show()

df_train.Education.value_counts()

"""## 2.8. Periksa data Status Pekerjaan / Self_Employed
No = 0

Yes = 1
"""

plt.hist(df_train.Self_Employed)
plt.show()

df_train.Self_Employed.value_counts()

"""## 2.9. Periksa data Pendapatan Applicant / ApplicantIncome"""

plt.hist(df_train.ApplicantIncome)
plt.show()

plt.scatter(range(0,len(df_train.index),1), df_train.ApplicantIncome)
plt.show()

df_train = df_train[df_train.ApplicantIncome <= 30000]
df_train

plt.hist(df_train.ApplicantIncome)
plt.show()

plt.scatter(range(0,len(df_train.index),1), df_train.ApplicantIncome)
plt.show()

"""## 2.10. Periksa data Pendapatan Pasangan Applicant / CoApplicantIncome"""

plt.hist(df_train.CoapplicantIncome)
plt.show()

plt.scatter(range(0,len(df_train.index),1), df_train.CoapplicantIncome)
plt.show()

df_train = df_train[df_train.CoapplicantIncome <= 15000]
df_train

plt.scatter(range(0,len(df_train.index),1), df_train.CoapplicantIncome)
plt.show()

"""## 2.11. Periksa data Jumlah Pinjaman / LoanAmount"""

plt.hist(df_train.LoanAmount)
plt.show()

plt.scatter(range(0,len(df_train.index),1), df_train.LoanAmount)
plt.show()

"""## 2.12. Periksa data Tenor Pinjaman / LoanAmountTerm"""

plt.hist(df_train.Loan_Amount_Term)
plt.show()

plt.scatter(range(0,len(df_train.index),1), df_train.Loan_Amount_Term)
plt.show()

"""## 2.13. Periksa data Credit History / CreditHistory"""

plt.hist(df_train.Credit_History)
plt.show()

"""## 2.14. Periksa data Area Properti / Property Area
Rural = 0

Semi Urban = 1

Urban = 2
"""

plt.hist(df_train.Property_Area)
plt.show()

"""## 2.15. Buat diagram heatmap
Diagram heatmap berguna untuk memvisualisasikan korelasi antar-fitur sehingga kita dengan mudah dapat melihat keterkaitan-keterkaitan antara fitur mana yang kuat dan cukup signifikan.
Diagram heatmap ini juga berguna untuk melakukan pemeriksaan apakah semua fitur sudah kita ubah nilainya menjadi numerikal, karena fitur kategorikal tidak akan dipetakan di diagram ini.
"""

import seaborn as sns

sns.set_style('dark')
plt.figure(figsize=(12,8))
sns.heatmap(df_train.corr(), cmap='coolwarm', annot=True, fmt='.1f', linewidths=.1)
plt.show()

"""# 3. Memisahkan data training dan validasi. """

import sklearn.model_selection as ms

features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area']
X = df_train[features]
y = df_train.Loan_Status

X_train, X_val, y_train, y_val = ms.train_test_split(X, y, test_size=0.2, random_state = 0)

"""# 4. Membuat model logistic regression."""

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

pipe = make_pipeline(StandardScaler(), LogisticRegression(solver = "lbfgs"))
pipe.fit(X_train, y_train)  # apply scaling on training data
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('logisticregression', LogisticRegression(solver = "lbfgs"))])

pipe.score(X_val, y_val) 

#model = lm.LogisticRegression(solver="lbfgs")
#model.fit(X_train, y_train)

"""# 5. Melakukan validasi."""

y_pred = pipe.predict(X_val)
print(y_pred)

df_y_pred = pd.DataFrame(y_pred)
df_y_pred.value_counts()

"""# 6. Mengukur performa model Logistic Regression

## 6.1. Mean Squared Error (MSE)

Metrik pengukuran performa pertama yang dipakai adalah Mean Squared Error (MSE). Metrik ini mengkuadratkan perbedaan nilai antara prediksi dan aktual, lalu mengambil nilai akhir rata-ratanya.
"""

models = pd.DataFrame(index=['train_mse', 'test_mse', 'accuracy', 'precision', 'sensitivity', 'roc_auc'], 
                      columns=['Logistic Regression'])

from sklearn.metrics import mean_squared_error

models.loc['train_mse','Logistic Regression'] = mean_squared_error(y_pred = pipe.predict(X_train), y_true=y_train)

models.loc['test_mse','Logistic Regression'] = mean_squared_error(y_pred = pipe.predict(X_val), y_true=y_val)

models

"""## 6.2. Confusion Matrix

Matrix ini memetakan hasil prediksi ke dalam beberapa kategori, antara lain:
1. True Positive  - nilai prediksi 1, nilai aktual 1.
2. True Negative  - nilai prediksi 0, nilai aktual 0.
3. False Positive - nilai prediksi 1, nilai aktual 0
4. False Negative - nilai prediksi 0, nilai aktual 1
"""

from sklearn.metrics import confusion_matrix

cf_matrix = confusion_matrix(y_val, y_pred)
print(cf_matrix)

"""### 6.2.1 Akurasi

Akurasi diukur dengan rumus = (TP + TN)/(TP + TN + FP + FN)
"""

score = pipe.score(X_val, y_val)
print(score)

models.loc['accuracy','Logistic Regression'] = score

"""### 6.2.2 Presisi

Presisi diukur dengan rumus = TP / (TP + FP)
"""

import sklearn.metrics as met

precision = met.precision_score(y_val, y_pred)
print(precision)

models.loc['precision','Logistic Regression'] = precision

"""### 6.2.3 Sensitivitas

Sensitivitas diukur dengan rumus = TP / (TP + FN)
"""

sensitivity = met.recall_score(y_val, y_pred)
print(sensitivity)

models.loc['sensitivity','Logistic Regression'] = sensitivity

"""### 6.2.4 Area dibawah Kurva

Area dibawah kurva (area under the curve) atau yang disebut juga dengan auc dipakai sebagai ukuran untuk menilai baik atau buruknya suatu model. AUC mendekati 1 berarti bahwa model tersebut memiliki performa baik, sedangkan AUC mendekati 0.5 menandakan bahwa model memiliki performa buruk.
"""

auc_val = met.roc_auc_score(y_val, y_pred)
print(auc_val)

models.loc['roc_auc','Logistic Regression'] = auc_val

models

"""### 6.2.5. Kurva ROC"""

import matplotlib.pyplot as plt
y_pred_proba = pipe.predict_proba(X_val)[::, 1]
fp, tp, _ = met.roc_curve(y_val, y_pred_proba)
auc = met.roc_auc_score(y_val, y_pred_proba)
plt.plot(fp, tp, label = "auc_score = {}".format(auc))
plt.legend(loc=4)
plt.show()

"""# 7. Simpan model Logistic Regression"""

import pickle as pkl

pipe.fit(X_train, y_train)

# Menyimpan model ke media penyimpanan

filename = 'logistic_regression_model.sav'
pkl.dump(pipe, open(filename, 'wb'))
pipe.score(X_train, y_train)

# Membuka model dari media penyimpanan

loaded_pipe = pkl.load(open(filename, 'rb'))
result = loaded_pipe.score(X_train, y_train)
print(result)

"""# 8. Implementasi Algoritma Random Forest"""

from sklearn.ensemble import RandomForestRegressor
 
# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=12, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
 
models.loc['train_mse','Random Forest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)       
models.loc['test_mse','Random Forest'] = mean_squared_error(y_pred=RF.predict(X_val), y_true=y_val)

models

"""## 8.1. Prediksi dari algoritma Random Forest"""

y_pred = RF.predict(X_val)
y_pred

"""## 8.2. Ubah nilai score Random Forest ke nilai binomial"""

y_pred_new = []
for val in y_pred:
    if (val > 0.5): val = 1 
    else: val = 0
    y_pred_new.append(val)

print(y_pred_new)

"""# 9. Mengukur performa model Random Forest

## 9.1. Mean Squared Error (MSE)
"""

models.loc['train_mse','Random Forest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)       
models.loc['test_mse','Random Forest'] = mean_squared_error(y_pred=RF.predict(X_val), y_true=y_val)

models

"""## 9.2. Confusion Matrix"""

cf_matrix = confusion_matrix(y_val, y_pred_new)
print(cf_matrix)

"""### 9.2.1. Akurasi"""

score = met.accuracy_score(y_val, y_pred_new)
print(score)

models.loc['accuracy','Random Forest'] = score

"""### 9.2.2. Presisi"""

precision = met.precision_score(y_val, y_pred_new)
print(precision)

models.loc['precision','Random Forest'] = precision

"""### 9.2.3. Sensitivitas"""

sensitivity = met.recall_score(y_val, y_pred_new)
print(sensitivity)

models.loc['sensitivity','Random Forest'] = sensitivity

"""### 9.2.4. Area dibawah kurva (AUC)"""

auc_val = met.roc_auc_score(y_val, y_pred_new)
print(auc_val)

models.loc['roc_auc','Random Forest'] = auc_val

models

"""### 9.2.5. Kurva ROC"""

import matplotlib.pyplot as plt
y_pred_proba = RF.predict(X_val)
fp, tp, _ = met.roc_curve(y_val, y_pred_proba)
auc = met.roc_auc_score(y_val, y_pred_proba)
plt.plot(fp, tp, label = "auc_score = {}".format(auc))
plt.legend(loc=4)
plt.show()

"""# 10. Simpan model Random Forest"""

RF.fit(X_train, y_train)

# Menyimpan model ke media penyimpanan

filename = 'random_forest_model.sav'
pkl.dump(RF, open(filename, 'wb'))
RF.score(X_train, y_train)

# Membuka model dari media penyimpanan

loaded_rf = pkl.load(open(filename, 'rb'))
result = loaded_rf.score(X_train, y_train)
print(result)

"""# 11. Implementasi Algoritma Boosting"""

from sklearn.ensemble import AdaBoostRegressor
 
boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)
models.loc['test_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_val), y_true=y_val)

models

"""## 11.1. Prediksi algoritma boosting"""

y_pred_boost = boosting.predict(X_val)
y_pred_boost

"""## 11.2. Ubah hasil prediksi ke nilai binomial"""

y_pred_boost_new = []
for val in y_pred_boost:
    if (val > 0.5): val = 1 
    else: val = 0
    y_pred_boost_new.append(val)

print(y_pred_boost_new)

"""# 12. Mengukur performa model Algoritma Boosting

## 12.1. Mean Squared Error (MSE)
"""

models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)
models.loc['test_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_val), y_true=y_val)

models

"""## 12.2. Confusion Matrix"""

cf_matrix = confusion_matrix(y_val, y_pred_boost_new)
print(cf_matrix)

"""### 12.2.1. Akurasi"""

score = met.accuracy_score(y_val, y_pred_boost_new)
print(score)

models.loc['accuracy','Boosting'] = score

"""### 12.2.2. Presisi"""

precision = met.precision_score(y_val, y_pred_boost_new)
print(precision)

models.loc['precision','Boosting'] = precision

"""### 12.2.3. Sensitivitas"""

sensitivity = met.recall_score(y_val, y_pred_boost_new)
print(sensitivity)

models.loc['sensitivity','Boosting'] = sensitivity

"""### 12.2.4. Area dibawah kurva (AUC)"""

auc_val = met.roc_auc_score(y_val, y_pred_boost_new)
print(auc_val)

models.loc['roc_auc','Boosting'] = auc_val

models

"""### 12.2.5 Kurva ROC"""

import matplotlib.pyplot as plt
y_pred_proba = boosting.predict(X_val)
fp, tp, _ = met.roc_curve(y_val, y_pred_proba)
auc = met.roc_auc_score(y_val, y_pred_proba)
plt.plot(fp, tp, label = "auc_score = {}".format(auc))
plt.legend(loc=4)
plt.show()

"""# 13. Simpan model Algoritma Boosting"""

boosting.fit(X_train, y_train)

# Menyimpan model ke media penyimpanan

filename = 'boosting_model.sav'
pkl.dump(boosting, open(filename, 'wb'))
boosting.score(X_train, y_train)

# Membuka model dari media penyimpanan

loaded_boost = pkl.load(open(filename, 'rb'))
result = loaded_boost.score(X_train, y_train)
print(result)

"""# 14. Evaluasi model machine learning"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['Logistic Regression','Random Forest','Boosting'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'Logistic Regression': pipe, 'Random Forest': RF, 'Boosting': boosting}
 
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_val, y_pred=model.predict(X_val))/1e3
 
# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediction = X_val.iloc[:1].copy()
pred_dict = {'y_true':y_val[:1]}
for name, model in model_dict.items():
    pred_dict['prediction_'+name] = model.predict(prediction).round(1)
 
pd.DataFrame(pred_dict)