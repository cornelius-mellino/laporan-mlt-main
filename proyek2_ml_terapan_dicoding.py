# -*- coding: utf-8 -*-
"""proyek2_ml_terapan_dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A504k-qEnlMWAvlPYZpj6YpNHt2aAZ4V

# Applied Machine Learning Project: Recommender System
## By: Cornelius Mellino Sarungu

## 1. Preparation
Import all necessary librares.
"""

# Import library
import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
import math

"""## 2. Define the Data URL
Set the data URL and load them.
"""

_data_url = 'https://raw.githubusercontent.com/cornelius-mellino/laporan-mlt-main/master/data/'
_file_movies = 'movies.csv'
_file_rating = 'Ratings.csv'

movies = pd.read_csv(_data_url + _file_movies)
rating = pd.read_csv(_data_url + _file_rating)

"""## 3. Data Understanding
Get into the data structure to understand more about it. In this stage we conduct some inspection steps and also resizing the dataset to gain the processing speed and avoid crash caused by the overloaded memory. The resizing won't affect the model because it works based on a simple algebraic calculation, unlike those which based on neural network that really depends on the data size.

## 3.1 Inspecting the movies dataframe.

### 3.1.1 Inspect part of the movies dataframe using head() function.
"""

movies.head()

"""### 3.1.2 Check the original length of the movies dataframe."""

len(movies)

"""### 3.1.3 Inspect the movies dataframe datastructure using info() function."""

movies.info()

"""### 3.1.4 For the experiment, cut the data to only 5000 rows to speed up the experiment process. (optional)"""

movies = movies[:5000]

"""### 3.1.5 Checkout the total unique movies in the movies dataframe."""

len(movies['title'].unique())

"""## 3.2 Inspecting the rating dataframe.

### 3.2.1 Inspect part of the rating dataframe using head() function.
"""

rating.head()

"""### 3.2.2 Inspect the rating portion on movies."""

rating.groupby(['rating']).sum().plot(kind='pie', y="movieId", autopct='%1.0f%%', figsize=(10, 10))

"""### 3.2.3 Inspect the rating portion on users."""

rating.groupby(['rating']).sum().plot(kind='pie', y="userId", autopct='%1.0f%%', figsize=(10, 10))

"""### 3.2.4 Top 20 users with highest count of movies watched."""

rating.groupby(['userId'], group_keys=False).count().sort_values(by="movieId", ascending=False)["movieId"][:20]

"""### 3.2.5 Top 20 movies with highest count of users."""

rating.groupby(['movieId'], group_keys=False).count().sort_values(by="userId", ascending=False)["userId"][:20]

"""### 3.2.6 Check the original length of the rating dataframe."""

len(rating)

"""### 3.2.7 Check the original unique user in the rating dataframe."""

len(rating['userId'].unique())

"""### 3.2.8 Check the original unique movies in the rating dataframe."""

len(rating['movieId'].unique())

"""### 3.2.9 For the experiment reduce the data size to 10000 to increase processing speed."""

rating = rating[:10000]

"""### 3.2.10 Inspect the total unique user involved in the newly reduced rating dataframe."""

len(rating['userId'].unique())

"""### 3.2.11 Inspect the total unique movies involved in the newly reduced rating dataframe."""

len(rating['movieId'].unique())

"""### 3.2.12 Reinspect the rating portion on users."""

rating.groupby(['rating']).sum().plot(kind='pie', y="userId", autopct='%1.0f%%', figsize=(10, 10))

"""### 3.2.13 Reinspect the rating portion on movies."""

rating.groupby(['rating']).sum().plot(kind='pie', y="movieId", autopct='%1.0f%%', figsize=(10, 10))

"""### 3.2.14 Rating data structure inspection"""

rating.info()

"""## 3.3 Re-inspect the total number of users, movies and ratings."""

# Mendapatkan jumlah user
num_users = len(rating["userId"].unique())
print(num_users)
 
# Mendapatkan jumlah movie
num_movie = len(rating["movieId"].unique())
print(num_movie)

# Mendapatkan jumlah rating
num_rating = len(rating["rating"])
print(num_rating)
 
# Nilai minimum rating
min_rating = min(rating['rating'])
 
# Nilai maksimal rating
max_rating = max(rating['rating'])
 
print('Number of User: {}, Number of Movie: {}, Number of Rating: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, num_rating, min_rating, max_rating
))

"""## 4. Data Preparation
Data must be prepared, and tidy up before processed into an analytic engine or algorithm. In this stage we do the transformation effort to shape the data into a ready-to-process form.

## 4.1 Check the data structure.
"""

print(rating.head())

print(movies.head())

rating.info()

movies.info()

"""## 4.2 Merge the rating and movie tables.

### 4.2.1 Merge the tables.
"""

complete_df = pd.merge(rating, movies, how='inner', left_on = 'movieId', right_on = 'movieId')

complete_df.info()

complete_df.head()

"""### 4.2.2 Check whether there are any duplicate data or not."""

complete_df["duplicate"] = complete_df.duplicated()
print(len(complete_df[complete_df["duplicate"] == False]))
print(len(complete_df[complete_df["duplicate"] == True]))

"""### 4.2.3 Check whether there are any missing values."""

# Cek missing value dengan fungsi isnull()
complete_df.isnull().sum()

complete_df["rating"].isnull().values.any()

"""## 4.3 Test to find out the total rating per movie."""

# Menghitung jumlah rating per movie
total_rating_per_movie_df = rating.groupby('movieId').sum()[["rating"]]
total_rating_per_movie_df = total_rating_per_movie_df.reset_index()
print(total_rating_per_movie_df.head())

"""# 5. Model Building.

## 5.1 Build method for calculating the Euclidian Distance.
"""

# Calculate the euclidean distance

def movie_euclidian_distance(dataset, user1, user2):
  data1 = dataset[dataset["userId"] == user1][["userId", "movieId", "rating"]]
  data2 = dataset[dataset["userId"] == user2][["userId", "movieId", "rating"]]

  similar_movie = pd.merge(dataset[dataset["userId"] == user1][["userId", "movieId", "rating"]], dataset[dataset["userId"] == user2][["userId", "movieId", "rating"]], on=['movieId'], how='inner')

  similar_movie["difference"] = similar_movie["rating_x"] - similar_movie["rating_y"]
  similar_movie["sqr_distance"] = similar_movie["difference"] * similar_movie["difference"]

  sum_euclidian = sum(similar_movie["sqr_distance"])

  return 1 / (1 + math.sqrt(sum_euclidian))

"""## 5.2 Build method for calculating similarities score."""

from datetime import datetime

def get_similarities(dataset, user):
  user_taken_out_df = dataset[dataset["userId"] != user]["userId"].unique()

  #now = datetime.now()
  #current_time = now.strftime("%H:%M:%S")

  similarity = [(movie_euclidian_distance(dataset, user, other), other) for other in user_taken_out_df if other != user]

  #now = datetime.now()
  #current_time = now.strftime("%H:%M:%S")

  similarity.sort()
  similarity.reverse()
  
  return pd.DataFrame (similarity, columns = ['similarity', 'userId'])

"""### 5.2.1 Testing the get_similarities() method."""

similarity_list = get_similarities(complete_df, 5)

print(similarity_list)

"""## 5.3 Build method to get the recommendation list for a user."""

def get_recommendation(dataset, user):
  similarity_temp_df = pd.DataFrame()
  movie_temp_df = pd.DataFrame()

  similarity_list = get_similarities(dataset, user)

  for row in dataset.index:

    if(dataset["userId"][row] == user):
      continue
    else:
      similarity_temp_df = similarity_temp_df.append( 
          {"userId": dataset["userId"][row], 
           "movieId": dataset["movieId"][row],
           "rating": dataset["rating"][row], 
           "similarity": similarity_list[similarity_list["userId"] == dataset["userId"][row]][["similarity"]].values[0][0],
           "similarity_x_rating": dataset["rating"][row] * similarity_list[similarity_list["userId"] == dataset["userId"][row]][["similarity"]].values[0][0]},
           ignore_index=True)

  movie_temp_df = similarity_temp_df.groupby("movieId").sum()[["similarity", "similarity_x_rating"]]
  movie_temp_df["score_per_movie"] = movie_temp_df["similarity_x_rating"] / movie_temp_df["similarity"]
  movie_temp_df.sort_values(by=["score_per_movie"], inplace=True, ascending=False)

  movie_temp_df.reset_index(inplace=True)
  movie_temp_df["title"] = ""

  for i in movie_temp_df.index:
    movie_temp_df.loc[i:, ["title"]] = dataset[dataset["movieId"] == movie_temp_df.loc[i:, ["movieId"]].values[0][0]][["title"]].values[0][0]
  #  print(movie_temp_df)
  
  return movie_temp_df

"""### 5.2.2 Testing the get_recommendation() method."""

print(get_recommendation(complete_df, 100)[1:10])

"""# 6. Evaluation.

## 6.1 Processing time measurement.
First attempt, extracting top 10 result.
"""

now1 = datetime.now()
t1 = now1.strftime("%H:%M:%S")
print("Start time: ", t1)

print(get_recommendation(complete_df, 100)[1:10])

now2 = datetime.now()
t2 = now2.strftime("%H:%M:%S")
# datetime.strptime
print("Finish time: ", t2)

delta = (now2-now1).total_seconds()
print("Processing duration: {} sec.".format(delta))

"""Second attempt, extracting all of the result."""

now1 = datetime.now()
t1 = now1.strftime("%H:%M:%S")
print("Start time: ", t1)

print(get_recommendation(complete_df, 100))

now2 = datetime.now()
t2 = now2.strftime("%H:%M:%S")
# datetime.strptime
print("Finish time: ", t2)

delta = (now2-now1).total_seconds()
print("Processing duration: {} sec.".format(delta))

"""Third attempt, testing with second user."""

now1 = datetime.now()
t1 = now1.strftime("%H:%M:%S")
print("Start time: ", t1)

print(get_recommendation(complete_df, 5))

now2 = datetime.now()
t2 = now2.strftime("%H:%M:%S")
# datetime.strptime
print("Finish time: ", t2)

delta = (now2-now1).total_seconds()
print("Processing duration: {} sec.".format(delta))

"""Fourth attempt, testing with third user."""

now1 = datetime.now()
t1 = now1.strftime("%H:%M:%S")
print("Start time: ", t1)

print(get_recommendation(complete_df, 20))

now2 = datetime.now()
t2 = now2.strftime("%H:%M:%S")
# datetime.strptime
print("Finish time: ", t2)

delta = (now2-now1).total_seconds()
print("Processing duration: {} sec.".format(delta))